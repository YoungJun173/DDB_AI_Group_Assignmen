{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ed07ed",
   "metadata": {},
   "source": [
    "This notebook contains all of our ideas for what should be included in the EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96d1ab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library Imports --- IGNORE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc72981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the files\n",
    "df_exreviews = pd.read_excel(os.path.join(\"..\", \"Metacritic dataset\", \"ExpertReviews.xlsx\"))\n",
    "df_metaclean = pd.read_excel(os.path.join(\"..\", \"Metacritic dataset\", \"metaClean43Brightspace.xlsx\"))\n",
    "df_sales = pd.read_excel(os.path.join(\"..\", \"Metacritic dataset\", \"sales.xlsx\"))\n",
    "df_usreviews = pd.read_excel(os.path.join(\"..\", \"Metacritic dataset\", \"UserReviews.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d6295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase, trim, remove special characters\n",
    "# df1\n",
    "\n",
    "\n",
    "def clean_text_column(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()                      # lowercase\n",
    "        text = text.strip()                      # remove spaces at start/end\n",
    "        text = re.sub(r'[^a-z0-9\\s]', '', text)  # remove special characters\n",
    "    return text\n",
    "for col in df1.columns:\n",
    "    df1[col] = df1[col].apply(clean_text_column)\n",
    "for col in df2.columns:\n",
    "    df2[col] = df2[col].apply(clean_text_column)  \n",
    "for col in df3.columns:\n",
    "    df3[col] = df3[col].apply(clean_text_column)  \n",
    "for col in df4.columns:\n",
    "    df4[col] = df4[col].apply(clean_text_column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b16e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows and columns in df3\n",
    "print(\"There are {} rows and {} columns in UserReviews\".format(df3.shape[0], df3.shape[1]))\n",
    "print(\"There are {} rows and {} columns in ExpertReviews\".format(df4.shape[0], df4.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb5149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick overview of the dataset by looking at the first and last few rows df3\n",
    "df3.head()\n",
    "df3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f85fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick overview of the dataset by looking at the first and last few rows df4\n",
    "df4.head()\n",
    "df4.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5311c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the unique df3\n",
    "print(\"Is URL column unique? :\", df3['url'].is_unique)\n",
    "print(\"Number of duplicate URLs:\", df3['url'].duplicated().sum())\n",
    "print(\"Number of unique URLs   :\", df3['url'].nunique())\n",
    "print(\"Total number of rows    :\", df3.shape[0])\n",
    "\n",
    "print(\"Is URL column unique? :\", df3['reviewer'].is_unique)\n",
    "print(\"Number of duplicate URLs:\", df3['reviewer'].duplicated().sum())\n",
    "print(\"Number of unique URLs   :\", df3['reviewer'].nunique())\n",
    "print(\"Total number of rows    :\", df3.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deab23ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the unique df4\n",
    "print(\"Is URL column unique? :\", df4['url'].is_unique)\n",
    "print(\"Number of duplicate URLs:\", df4['url'].duplicated().sum())\n",
    "print(\"Number of unique URLs   :\", df4['url'].nunique())\n",
    "print(\"Total number of rows    :\", df4.shape[0])\n",
    "\n",
    "print(\"Is URL column unique? :\", df4['reviewer'].is_unique)\n",
    "print(\"Number of duplicate URLs:\", df4['reviewer'].duplicated().sum())\n",
    "print(\"Number of unique URLs   :\", df4['reviewer'].nunique())\n",
    "print(\"Total number of rows    :\", df4.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbb2f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values df3\n",
    "n_nulls_df3 = df3.loc[lambda x: x.isnull().any(axis=1)].shape\n",
    "print(f\"There are {n_nulls_df3[0]} rows with missing values in df3\")\n",
    "df3.isna().sum()\n",
    "# 1. Drop rows missing review text\n",
    "df3 = df3.dropna(subset=['Rev']).copy()\n",
    "\n",
    "# 2. Fill missing reviewer names\n",
    "df3.loc[:, 'reviewer'] = df3['reviewer'].fillna('unknown_reviewer')\n",
    "\n",
    "# 3. Fill missing score only if needed\n",
    "# df3.loc[:, 'idvscore'] = df3['idvscore'].fillna(-1)  # or drop them if needed\n",
    "\n",
    "# 4. Replace missing thumbsUp and thumbsTot with 0\n",
    "df3.loc[:, 'thumbsUp'] = df3['thumbsUp'].fillna(0)\n",
    "df3.loc[:, 'thumbsTot'] = df3['thumbsTot'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a9d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Check missing values \n",
    "n_nulls_df4 = df4.loc[lambda x: x.isnull().any(axis=1)].shape\n",
    "print(f\"There are {n_nulls_df4[0]} rows with missing values in df4\")\n",
    "\n",
    "print(\"\\nMissing values per column before cleaning:\")\n",
    "print(df4.isna().sum())\n",
    "\n",
    "#  Drop rows where review text is missing \n",
    "df4 = df4.dropna(subset=['Rev']).copy()\n",
    "\n",
    "#  Fill optional missing values \n",
    "\n",
    "df4.loc[:, 'reviewer'] = df4['reviewer'].fillna('unknown_reviewer')\n",
    "\n",
    "# Missing date \n",
    "df4.loc[:, 'dateP'] = df4['dateP'].fillna('unknown_date')\n",
    "\n",
    "# Check again after cleaning\n",
    "print(\"\\nMissing values per column after cleaning:\")\n",
    "print(df4.isna().sum())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIForBusiness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
