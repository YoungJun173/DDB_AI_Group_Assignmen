{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ed07ed",
   "metadata": {},
   "source": [
    "This notebook contains all of our ideas for what should be included in the EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96d1ab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library Imports --- IGNORE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc72981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jun - Reading the files\n",
    "df_exreviews = pd.read_excel(os.path.join(\"..\", \"Metacritic dataset\", \"ExpertReviews.xlsx\"))\n",
    "df_metaclean = pd.read_excel(os.path.join(\"..\", \"Metacritic dataset\", \"metaClean43Brightspace.xlsx\"))\n",
    "df_sales = pd.read_excel(os.path.join(\"..\", \"Metacritic dataset\", \"sales.xlsx\"))\n",
    "df_usreviews = pd.read_excel(os.path.join(\"..\", \"Metacritic dataset\", \"UserReviews.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d6295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rosie - Lowercase, trim, remove special characters\n",
    "# df1\n",
    "\n",
    "\n",
    "def clean_text_column(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()                      # lowercase\n",
    "        text = text.strip()                      # remove spaces at start/end\n",
    "        text = re.sub(r'[^a-z0-9\\s]', '', text)  # remove special characters\n",
    "    return text\n",
    "for col in df1.columns:\n",
    "    df1[col] = df1[col].apply(clean_text_column)\n",
    "for col in df2.columns:\n",
    "    df2[col] = df2[col].apply(clean_text_column)  \n",
    "for col in df3.columns:\n",
    "    df3[col] = df3[col].apply(clean_text_column)  \n",
    "for col in df4.columns:\n",
    "    df4[col] = df4[col].apply(clean_text_column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b16e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rosie - number of rows and columns in df3\n",
    "print(\"There are {} rows and {} columns in UserReviews\".format(df3.shape[0], df3.shape[1]))\n",
    "print(\"There are {} rows and {} columns in ExpertReviews\".format(df4.shape[0], df4.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb5149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rosie - a quick overview of the dataset by looking at the first and last few rows df3\n",
    "df3.head()\n",
    "df3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f85fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rosie - a quick overview of the dataset by looking at the first and last few rows df4\n",
    "df4.head()\n",
    "df4.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5311c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rosie - check the unique df3\n",
    "print(\"Is URL column unique? :\", df3['url'].is_unique)\n",
    "print(\"Number of duplicate URLs:\", df3['url'].duplicated().sum())\n",
    "print(\"Number of unique URLs   :\", df3['url'].nunique())\n",
    "print(\"Total number of rows    :\", df3.shape[0])\n",
    "\n",
    "print(\"Is URL column unique? :\", df3['reviewer'].is_unique)\n",
    "print(\"Number of duplicate URLs:\", df3['reviewer'].duplicated().sum())\n",
    "print(\"Number of unique URLs   :\", df3['reviewer'].nunique())\n",
    "print(\"Total number of rows    :\", df3.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deab23ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rosie - check the unique df4\n",
    "print(\"Is URL column unique? :\", df4['url'].is_unique)\n",
    "print(\"Number of duplicate URLs:\", df4['url'].duplicated().sum())\n",
    "print(\"Number of unique URLs   :\", df4['url'].nunique())\n",
    "print(\"Total number of rows    :\", df4.shape[0])\n",
    "\n",
    "print(\"Is URL column unique? :\", df4['reviewer'].is_unique)\n",
    "print(\"Number of duplicate URLs:\", df4['reviewer'].duplicated().sum())\n",
    "print(\"Number of unique URLs   :\", df4['reviewer'].nunique())\n",
    "print(\"Total number of rows    :\", df4.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbb2f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rosie - missing values df3\n",
    "n_nulls_df3 = df3.loc[lambda x: x.isnull().any(axis=1)].shape\n",
    "print(f\"There are {n_nulls_df3[0]} rows with missing values in df3\")\n",
    "df3.isna().sum()\n",
    "# 1. Drop rows missing review text\n",
    "df3 = df3.dropna(subset=['Rev']).copy()\n",
    "\n",
    "# 2. Fill missing reviewer names\n",
    "df3.loc[:, 'reviewer'] = df3['reviewer'].fillna('unknown_reviewer')\n",
    "\n",
    "# 3. Fill missing score only if needed\n",
    "# df3.loc[:, 'idvscore'] = df3['idvscore'].fillna(-1)  # or drop them if needed\n",
    "\n",
    "# 4. Replace missing thumbsUp and thumbsTot with 0\n",
    "df3.loc[:, 'thumbsUp'] = df3['thumbsUp'].fillna(0)\n",
    "df3.loc[:, 'thumbsTot'] = df3['thumbsTot'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a9d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Rosie - Check missing values \n",
    "n_nulls_df4 = df4.loc[lambda x: x.isnull().any(axis=1)].shape\n",
    "print(f\"There are {n_nulls_df4[0]} rows with missing values in df4\")\n",
    "\n",
    "print(\"\\nMissing values per column before cleaning:\")\n",
    "print(df4.isna().sum())\n",
    "\n",
    "#  Drop rows where review text is missing \n",
    "df4 = df4.dropna(subset=['Rev']).copy()\n",
    "\n",
    "#  Fill optional missing values \n",
    "\n",
    "df4.loc[:, 'reviewer'] = df4['reviewer'].fillna('unknown_reviewer')\n",
    "\n",
    "# Missing date \n",
    "df4.loc[:, 'dateP'] = df4['dateP'].fillna('unknown_date')\n",
    "\n",
    "# Check again after cleaning\n",
    "print(\"\\nMissing values per column after cleaning:\")\n",
    "print(df4.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1100cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iro - Clean column names from sales \n",
    "sales.columns = (\n",
    "    sales.columns\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(\" \", \"_\") \n",
    "    .str.replace(r\"[^0-9a-z_]\", \"\", regex=True)\n",
    ")\n",
    "sales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01947f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iro - Clean text column from sales \n",
    "text_cols = [\"title\", \"genre\", \"keywords\", \"creative_type\", \"url\"]\n",
    "\n",
    "for col in text_cols:\n",
    "    if col in sales.columns:\n",
    "        sales[col] = (\n",
    "            sales[col].astype(str)\n",
    "            .str.lower()\n",
    "            .str.strip()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9163eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iro - Convert numeric columns\n",
    "num_cols = [\n",
    "    \"domestic_box_office\", \"international_box_office\", \"worldwide_box_office\",\n",
    "    \"production_budget\", \"opening_weekend\", \"theatre_count\",\n",
    "    \"avg_run_per_theatre\", \"runtime\", \"year\"\n",
    "]\n",
    "\n",
    "for col in num_cols:\n",
    "    if col in sales.columns:\n",
    "        sales[col] = pd.to_numeric(sales[col], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613d6d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iro - Missing value summary\n",
    "sales.isna().sum() # how many missing values each column has"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9daa1e",
   "metadata": {},
   "source": [
    "Data quality:\n",
    "- production_budget → 26,132 missing\n",
    "- domestic_box_office → 18,728 missing\n",
    "- international_box_office → 9,037 missing\n",
    "- unnamed_8 → 30,612 missing \n",
    "\n",
    "Usable columns:\n",
    "- year, title, genre → 0 missing \n",
    "- runtime → 6,053 missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c643a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iro - Plot sales distributions\n",
    "cols = [\"domestic_box_office\", \"international_box_office\", \"worldwide_box_office\"]\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "notation = (\n",
    "    \"Axis meaning:\\n\"\n",
    "    \"0   →   0\\n\"\n",
    "    \"0.5 → 500M\\n\"\n",
    "    \"1.0 → 1B\\n\"\n",
    "    \"2.0 → 2B\"\n",
    ")\n",
    "\n",
    "for ax, col in zip(axes, cols):\n",
    "    if col in sales.columns:\n",
    "        _ = ax.hist(sales[col].dropna(), bins=40)\n",
    "        _ = ax.set_title(col.replace(\"_\", \" \").title())\n",
    "        _ = ax.set_xlabel(\"Sales (USD)\")\n",
    "        _ = ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "        # suppress printed return value\n",
    "        _ = ax.text(\n",
    "            0.98, 0.98,\n",
    "            notation,\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=8,\n",
    "            ha='right',\n",
    "            va='top',\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.7)\n",
    "        )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465fb29f",
   "metadata": {},
   "source": [
    "**Interpretation of the Box Office Histograms**\n",
    "\n",
    "The three histograms (Domestic, International, and Worldwide Box Office) show how movie revenues are distributed.\n",
    "- The x-axis represents sales in USD, but very large values are shown in compressed scientific notation. The legend explains that values like 0.5, 1.0, 2.0 actually correspond to 500M, 1B, and 2B USD.\n",
    "- The y-axis, labeled Frequency, indicates how many movies fall into each revenue range (bin). A higher bar means more movies in that sales interval.\n",
    "\n",
    "Across all three charts, the very tall bar near zero shows that most movies earn very little revenue, while only a small number reach hundreds of millions or billions. This creates a long right tail, indicating that box office revenues are extremely skewed, with many low-earning films and a few very high-earning blockbusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3334c865",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIForBusiness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
